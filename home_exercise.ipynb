{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exporting graphs as html:\n",
    "import plotly.io as pio\n",
    "\n",
    "# This ensures Plotly output works in multiple places:\n",
    "# plotly_mimetype: VS Code notebook UI\n",
    "# notebook: \"Jupyter: Export to HTML\" command in VS Code\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage.measure\n",
    "from scipy.special import expit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import local packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = True\n",
    "analysis = False\n",
    "\n",
    "from utils import ls2pc, ls2ft, calc_lin_char"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recording from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv:\n",
    "file_name, lookingUp = 'rec_11c.csv', False\n",
    "table = pd.read_table(file_name, delimiter=',')\n",
    "\n",
    "table.iloc[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "1. tick is the time column (in milliseconds)\n",
    "2. stateEstimate.x and stateEstimate.y are the (x,y) coordinates of spot in meters.\n",
    "3. stateEstimate.yaw is spots orientation in degrees.\n",
    "4. The fields {mr18.m0, mr18.m1, ..., mr18.m15} are the range measurements in millimeters. Ranges above 4000 are measurement errors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert recorded data into desired physical units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = table['tick'].to_numpy()\n",
    "time -= time[0]\n",
    "Ts = np.median(np.diff(time, 1))\n",
    "print(f'original Ts={1000.0*Ts} [ms], time is [{time[0]},{time[-1]}]')\n",
    "\n",
    "ranges = table[[f'mr18.m{i}' for i in range(16)]].to_numpy(dtype=float)*0.001\n",
    "x = table['stateEstimate.x'].to_numpy()\n",
    "y = table['stateEstimate.y'].to_numpy()\n",
    "\n",
    "# unwrap angle:\n",
    "t = np.unwrap(np.deg2rad(table['stateEstimate.yaw'].to_numpy()))\n",
    "print(f'ranges shape before reduction: {ranges.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### down-sample\n",
    "if needed, downsample the recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# down-sample:\n",
    "D = 1\n",
    "if D>1:\n",
    "    ranges = skimage.measure.block_reduce(ranges, (D,1), np.max)\n",
    "    print(f'ranges shape after D=({D},1) reduction: {ranges.shape}')\n",
    "    x = skimage.measure.block_reduce(x, (D,), np.median)\n",
    "    y = skimage.measure.block_reduce(y, (D,), np.median)\n",
    "    t = skimage.measure.block_reduce(t, (D,), np.median)\n",
    "    time = skimage.measure.block_reduce(time, (D,), np.max)\n",
    "\n",
    "Ts = np.median(np.diff(time, 1))\n",
    "print(f'downsampled Ts={1000.0*Ts} [ms]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the x,y coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,16), dpi=200)\n",
    "plt.plot(x[::31], y[::31], '-b.', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laser Scan Vs Point Cloud\n",
    "*ls2pc* - converts ranges to their corresponding x,y coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a laser scan (LS) range array:\n",
    "range_ = np.array([[1,1,2,3,4,5,6,7,11,7,6,5,4,3,2,1]])\n",
    "# convert the LS to point cloud, using the information about the sensor orientations relative to each other:\n",
    "x_origin = np.array([0])\n",
    "y_origin = np.array([0])\n",
    "yaw = np.array([0])\n",
    "\n",
    "pc_x_r_, pc_y_r_, valid_inds_bool_, valid_inds_ = ls2pc(x_origin, y_origin, yaw, range_)\n",
    "\n",
    "# plot the point cloud\n",
    "plt.figure(figsize=(24,16), dpi=100)\n",
    "plt.plot(pc_x_r_, pc_y_r_, 'm.', markersize=16)\n",
    "plt.plot(0, 0, '-b.', markersize=5)\n",
    "plt.show()\n",
    "\n",
    "# play arround with the other inputs of ls2pc: x_origin, y_origin, yaw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the laser scanner data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert laser scan (16 ranges) to point cloud (2x16 xy coordinates)\n",
    "pc_x_r_, pc_y_r_, valid_inds_bool_, valid_inds_ = ls2pc(x, y, t, ranges)\n",
    "plt.figure(figsize=(24,16), dpi=200)\n",
    "plt.plot(pc_x_r_[valid_inds_bool_][::31], pc_y_r_[valid_inds_bool_][::31], 'm.', markersize=1)\n",
    "plt.plot(x[::31], y[::31], '-b.', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crate a database of all measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 20.0\n",
    "if all_data:\n",
    "    database = [\\\n",
    "    ('rec_08c.csv'),\n",
    "    ('rec_12c.csv'),\n",
    "    ('rec_11c.csv'),\n",
    "    ]\n",
    "    prev_i = 0\n",
    "    for i, (file_name) in enumerate(database):\n",
    "        table = pd.read_table(file_name, delimiter=',')\n",
    "\n",
    "        ranges_i = table[[f'mr18.m{i}' for i in range(16)]].to_numpy(dtype=float)*0.001\n",
    "        x_i = table['stateEstimate.x'].to_numpy()\n",
    "        y_i = table['stateEstimate.y'].to_numpy()\n",
    "        t_i = np.unwrap(np.deg2rad(table['stateEstimate.yaw'].to_numpy()))\n",
    "        pc_x_r_i, pc_y_r_i, valid_inds_bool_i, valid_inds_i = ls2pc(x_i, y_i, t_i, ranges_i)\n",
    "        if i>0:\n",
    "            prev_i = len(x_)\n",
    "            print(f'prev_i={prev_i}')\n",
    "            ranges_ = np.concatenate((ranges_, ranges_i), axis=0)\n",
    "            x_ = np.concatenate((x_, x_i+i*d), axis=0)\n",
    "            y_ = np.concatenate((y_, y_i), axis=0)\n",
    "            t_ = np.concatenate((t_, t_i), axis=0)\n",
    "            pc_x_r_ = np.concatenate((pc_x_r_, pc_x_r_i+i*d), axis=1)\n",
    "            pc_y_r_ = np.concatenate((pc_y_r_, pc_y_r_i), axis=1)\n",
    "            valid_inds_bool_ = np.concatenate((valid_inds_bool_, valid_inds_bool_i), axis=1)\n",
    "            valid_inds_ = np.concatenate((valid_inds_, valid_inds_i+prev_i), axis=0)\n",
    "        else:\n",
    "            ranges_ = ranges_i\n",
    "            x_ = x_i\n",
    "            y_ = y_i\n",
    "            t_ = t_i\n",
    "            pc_x_r_ = pc_x_r_i\n",
    "            pc_y_r_ = pc_y_r_i\n",
    "            valid_inds_bool_ = valid_inds_bool_i\n",
    "            valid_inds_ = valid_inds_i\n",
    "\n",
    "    print(f'total ranges shape: {ranges_.shape}')\n",
    "    if True:\n",
    "        plt.figure(figsize=(24,16), dpi=200)\n",
    "        plt.plot(pc_x_r_[valid_inds_bool_][::31], pc_y_r_[valid_inds_bool_][::31], 'm.', markersize=1)\n",
    "        plt.plot(x_[::31], y_[::31], '-b.', markersize=5)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert laser scans to point cloud:\n",
    "pc_x_r, pc_y_r, valid_inds_bool, valid_inds = ls2pc(x, y, t, ranges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot scene using plotly instead of pyplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mrkr = dict(color='LightSkyBlue', size=2,line=dict(color='MediumPurple', width=0.3))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=pc_x_r[valid_inds_bool][::11], y=pc_y_r[valid_inds_bool][::11], name='walls', mode='markers', marker_color=valid_inds[::11], marker=mrkr),\n",
    "    row=1, col=1\n",
    ")\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=x[::31], y=y[::31], name='trj'),\n",
    "#     row=1, col=1\n",
    "# )\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x[::31], y=y[::31], name='trj', mode='markers', marker_color=np.arange(len(x))[::31], line=dict(width=1, color='DarkSlateGrey')),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    scaleanchor=\"x\",\n",
    "    scaleratio=1,\n",
    ")\n",
    "fig.update_layout(height=600, width=800, title_text=\"Side By Side Subplots\")\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test total (all recordings) range measurements characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_data:\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=ranges_[::21,0], name='ranges 0'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=np.convolve([1,1,1], np.diff(ranges_[:,3], axis=0)==0), name='ranges 0'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_layout(height=600, width=800, title_text=\"Side By Side Subplots\")\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a few filtered laser scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = 125.0\n",
    "t0 = 105.0\n",
    "# t0 = 85.0\n",
    "# t0 = 180.0\n",
    "i0 = np.where(time>t0)[0][0]\n",
    "\n",
    "rs = ranges[[i0],:]\n",
    "# rs = ranges[[time_intrvl[0]],:]\n",
    "\n",
    "sig_1 = np.roll(rs, -1)\n",
    "sig_2 = np.roll(rs, 1)\n",
    "\n",
    "sig_1_mat = np.roll(ranges, -1, axis=1)\n",
    "sig_2_mat = np.roll(ranges, 1, axis=1)\n",
    "sig_3_mat = np.roll(ranges, -2, axis=1)\n",
    "sig_4_mat = np.roll(ranges, 3, axis=1)\n",
    "# rs_med3_mat = np.median(np.concatenate((ranges, sig_1_mat, sig_2_mat), axis=0), axis=0)\n",
    "print(sig_2.shape)\n",
    "rs_med3 = np.median(np.concatenate((rs, sig_1, sig_2), axis=0), axis=0)\n",
    "sig_3 = np.roll(rs, -2)\n",
    "sig_4 = np.roll(rs, 2)\n",
    "rs_med5 = np.median(np.concatenate((rs, sig_1, sig_2, sig_3, sig_4), axis=0), axis=0)\n",
    "\n",
    "fig = make_subplots(rows=4, cols=1)  #, subplot_titles=('ranges','without odom'))\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=rs[0,:], name='ranges'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=rs_med3, name='med3'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=rs[0,:]-rs_med3, name='diff'),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=rs_med5, name='med5'),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=rs[0,:]-rs_med5, name='diff'),\n",
    "    row=4, col=1\n",
    ")\n",
    "fig.update_layout(width=600, title_text=\"local laser scan\")\n",
    "fig.show()\n",
    "\n",
    "feature_1 = np.sum(np.abs(rs[0,:]-rs_med3)>0.5)\n",
    "feature_2 = np.sum(np.abs(rs[0,:]-rs_med3)>1.0)\n",
    "feature_3 = np.sum(np.abs(rs[0,:]-rs_med3)>1.5)\n",
    "\n",
    "feature_3 = feature_3 - feature_2\n",
    "feature_2 = feature_2 - feature_1\n",
    "\n",
    "feature_4 = np.array(rs[0,:]>4.0, dtype=float)\n",
    "feature_4 = np.sum(feature_4-np.roll(feature_4, 1)>0)\n",
    "\n",
    "feature_5 = np.array(rs_med5>4.0, dtype=float)\n",
    "feature_5 = np.sum(feature_5-np.roll(feature_5, 1)>0)\n",
    "\n",
    "print(f'features = {feature_1}, {feature_2}, {feature_3}, {feature_4}, {feature_5}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore sigmoid function (for smoothness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sigmoid(percent_loc, percent_val):\n",
    "    assert(percent_val<1.0 and percent_val>0.5)\n",
    "    xx = np.linspace(-10,10,500)\n",
    "    yy = expit(xx)\n",
    "    # print(f'shape(np.where(yy>percent_val))={np.where(yy>percent_val)[0].shape}')\n",
    "    s = np.where(yy>percent_val)[0][0]\n",
    "    # print(f's={s}, (xx[s]={xx[s]})')\n",
    "    sf = xx[s]/percent_loc\n",
    "    def sig(x):\n",
    "        return expit(x*sf)\n",
    "    return sig\n",
    "\n",
    "xx = np.linspace(-10, 15,300)\n",
    "sgmd_1 = get_sigmoid(5.0,0.9)\n",
    "sgmd_2 = get_sigmoid(2.0,0.9)\n",
    "plt.figure()\n",
    "plt.plot(xx, sgmd_1(xx-5))\n",
    "plt.plot(xx, 1-(sgmd_2(xx-4)+sgmd_2(-4-xx)))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check different range features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5*(sig_7_mat+ranges<1.2)+0.5*(sig_7_mat+ranges<0.9)\n",
    "f_prev = lambda x: 0.5*(x<1.2)+0.5*(x<0.9)\n",
    "\n",
    "xx = np.linspace(0, 5,300)\n",
    "sgmd_close = get_sigmoid(percent_loc=0.2,percent_val=0.9)\n",
    "\n",
    "sgmd_close_0p1 = get_sigmoid(percent_loc=0.1,percent_val=0.9)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_dpi(100)\n",
    "fig.set_size_inches(14,4)\n",
    "ax1.plot(xx, sgmd_close(1.0-xx))\n",
    "ax1.plot(xx, sgmd_close(2.0-xx)-sgmd_close(1.0-xx))\n",
    "ax1.plot(xx, sgmd_close(3.0-xx)-sgmd_close(2.0-xx))\n",
    "ax1.plot(xx, sgmd_close(4-xx)-sgmd_close(3.0-xx))\n",
    "ax1.plot(xx, f_prev(xx))\n",
    "\n",
    "ax2.plot(xx, sgmd_close(0.5-xx))\n",
    "ax2.plot(xx, sgmd_close_0p1(1.0-xx)-sgmd_close_0p1(0.5-xx))\n",
    "ax2.plot(xx, sgmd_close_0p1(1.5-xx)-sgmd_close_0p1(1.0-xx))\n",
    "ax2.plot(xx, sgmd_close_0p1(2.0-xx)-sgmd_close_0p1(1.5-xx))\n",
    "ax2.plot(xx, f_prev(xx))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_7_mat = np.roll(ranges, 8, axis=1)\n",
    "\n",
    "sig_7 = sgmd_close(1.0-(sig_7_mat+ranges))\n",
    "feature_7_mat = np.sum(sig_7, axis=1)\n",
    "\n",
    "sig_8 = sgmd_close(2.0-(sig_7_mat+ranges))-sig_7\n",
    "feature_8_mat = np.sum(sig_8, axis=1)\n",
    "\n",
    "sig_9 = sgmd_close(3.0-(sig_7_mat+ranges))-sig_8\n",
    "feature_9_mat = np.sum(sig_9, axis=1)\n",
    "\n",
    "sig_10 = sgmd_close(4.0-(sig_7_mat+ranges))-sig_9\n",
    "feature_10_mat = np.sum(sig_10, axis=1)\n",
    "\n",
    "sig_11 = sgmd_close(5.0-(sig_7_mat+ranges))-sig_10\n",
    "feature_11_mat = np.sum(sig_11, axis=1)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5,1)\n",
    "ax1.plot(feature_7_mat)\n",
    "ax2.plot(feature_8_mat)\n",
    "ax3.plot(feature_9_mat)\n",
    "ax4.plot(feature_10_mat)\n",
    "ax5.plot(feature_11_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_med3_mat = np.median(np.concatenate((np.expand_dims(ranges,axis=2), np.expand_dims(sig_1_mat,axis=2), np.expand_dims(sig_2_mat,axis=2)), axis=2), axis=2)\n",
    "feature_4_mat = np.array(rs_med3_mat>3.0, dtype=float)\n",
    "feature_4_mat = np.sum(feature_4_mat-np.roll(feature_4_mat, 1, axis=1)>0, axis=1)\n",
    "sc4 = StandardScaler()\n",
    "feature_4_mat = sc4.fit_transform(np.expand_dims(feature_4_mat, axis=1))\n",
    "sgmd_close4 = get_sigmoid(percent_loc=0.7,percent_val=0.9)\n",
    "fm4_ = sgmd_close4(rs_med3_mat-3.0)\n",
    "fm4_ = np.sum(sgmd_close4(fm4_-np.roll(fm4_, 1, axis=1)-0.98), axis=1)\n",
    "sc4_ = StandardScaler()\n",
    "fm4_ = sc4_.fit_transform(np.expand_dims(fm4_, axis=1))\n",
    "plt.figure()\n",
    "plt.plot(feature_4_mat)\n",
    "plt.plot(fm4_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw, fw_count = calc_lin_char(pc_x_r, pc_y_r, ranges, th=0.2)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_dpi(100)\n",
    "fig.set_size_inches(14,4)\n",
    "# plt.plot(pc_x_r[valid_inds_bool__][::11], pc_y_r[valid_inds_bool__][::11], 'm.', markersize=1)\n",
    "ax1.scatter(x, y, c=fw, marker='o')\n",
    "ax2.scatter(x, y, c=fw_count, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature calculations on all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(ranges, pc_x_r, pc_y_r):\n",
    "    \n",
    "    # shift measurements:\n",
    "    sig_1_mat = np.roll(ranges, -1, axis=1)\n",
    "    sig_2_mat = np.roll(ranges, 1, axis=1)\n",
    "    sig_3_mat = np.roll(ranges, -2, axis=1)\n",
    "    sig_4_mat = np.roll(ranges, 3, axis=1)\n",
    "    sig_7_mat = np.roll(ranges, 8, axis=1)\n",
    "\n",
    "    # calculate median 3 and 5:\n",
    "    rs_med3_mat = np.median(np.concatenate((np.expand_dims(ranges,axis=2), np.expand_dims(sig_1_mat,axis=2), np.expand_dims(sig_2_mat,axis=2)), axis=2), axis=2)\n",
    "\n",
    "    rs_med5_mat = np.median(np.concatenate((np.expand_dims(ranges,axis=2),\n",
    "                                        np.expand_dims(sig_1_mat,axis=2),\n",
    "                                        np.expand_dims(sig_2_mat,axis=2),\n",
    "                                        np.expand_dims(sig_3_mat,axis=2),\n",
    "                                        np.expand_dims(sig_4_mat,axis=2)),\n",
    "                                        axis=2), axis=2)\n",
    "    \n",
    "    pc_x_r_matRoll1 = np.roll(pc_x_r, 1, axis=0)\n",
    "    pc_x_r_matRolln1 = np.roll(pc_x_r, -1, axis=0)\n",
    "    pc_y_r_matRoll1 = np.roll(pc_y_r, 1, axis=0)\n",
    "    pc_y_r_matRolln1 = np.roll(pc_y_r, -1, axis=0)\n",
    "\n",
    "    feature_2_mat =np.sum(0.5+0.5*np.tanh(4*np.multiply(np.abs(pc_x_r_matRoll1*0.5+pc_x_r_matRolln1*0.5-pc_x_r),(ranges.T<2.0))+np.multiply(np.abs(pc_y_r_matRoll1*0.5+pc_y_r_matRolln1*0.5-pc_y_r),(ranges.T<2.0))-0.3), axis=0).T\n",
    "\n",
    "    # feature_1_mat = np.sum(np.abs(ranges-rs_med3_mat)>1.0, axis=1)\n",
    "    simple_calc = False\n",
    "    if simple_calc:\n",
    "        sig_7 = 0.5*(sig_7_mat+ranges<1.2)+0.5*(sig_7_mat+ranges<0.9)\n",
    "        feature_7_mat = np.sum(sig_7, axis=1)\n",
    "    else:\n",
    "        sig_7 = sgmd_close(1.0-(sig_7_mat+ranges))\n",
    "        feature_7_mat = np.sum(sig_7, axis=1)\n",
    "\n",
    "    sig_7 = sgmd_close(1.0-(sig_7_mat+ranges))\n",
    "    feature_7_mat = np.sum(sig_7, axis=1)\n",
    "\n",
    "    sig_8 = sgmd_close(2.0-(sig_7_mat+ranges))-sig_7\n",
    "    feature_8_mat = np.sum(sig_8, axis=1)\n",
    "\n",
    "    sig_9 = sgmd_close(3.0-(sig_7_mat+ranges))-sig_8\n",
    "    feature_9_mat = np.sum(sig_9, axis=1)\n",
    "\n",
    "    sig_10 = sgmd_close(4.0-(sig_7_mat+ranges))-sig_9\n",
    "    feature_10_mat = np.sum(sig_10, axis=1)\n",
    "\n",
    "    sig_11 = sgmd_close(5.0-(sig_7_mat+ranges))-sig_10\n",
    "    feature_11_mat = np.sum(sig_11, axis=1)\n",
    "\n",
    "\n",
    "    feature_6_mat = np.sum(0.4*(np.abs(ranges-rs_med5_mat)>1.7)+0.3*(np.abs(ranges-rs_med5_mat)>1.2)+0.3*(np.abs(ranges-rs_med5_mat)>0.5), axis=1)\n",
    "    feature_3_mat = np.sum(np.logical_and(np.array(ranges<2.0,dtype=float), np.array(np.abs(0.5*sig_1_mat+0.5*sig_2_mat-ranges)<0.3,dtype=float)), axis=1)\n",
    "    feature_1_mat = np.sum(np.logical_and(np.array(ranges<2.0,dtype=float), np.array(np.abs(0.25*sig_3_mat+0.25*sig_4_mat+0.25*sig_1_mat+0.25*sig_2_mat-ranges)<0.3,dtype=float)), axis=1)\n",
    "\n",
    "    if True:\n",
    "        feature_4_mat = np.array(rs_med3_mat>3.0, dtype=float)\n",
    "        feature_4_mat = np.sum(feature_4_mat-np.roll(feature_4_mat, 1, axis=1)>0, axis=1)\n",
    "    else:\n",
    "        sgmd_close4 = get_sigmoid(percent_loc=0.7,percent_val=0.9)\n",
    "        fm4_ = sgmd_close4(rs_med3_mat-3.0)\n",
    "        feature_4_mat = np.sum(sgmd_close4(fm4_-np.roll(fm4_, 1, axis=1)-0.98), axis=1)\n",
    "\n",
    "\n",
    "    feature_5_mat = np.array(rs_med5_mat>3.0, dtype=float)\n",
    "    feature_5_mat = np.sum(feature_5_mat-np.roll(feature_5_mat, 1, axis=1)>0, axis=1)\n",
    "    d1 = feature_4_mat*0.5+0.5*feature_5_mat\n",
    "    d2 = feature_2_mat\n",
    "    d3 = feature_1_mat\n",
    "\n",
    "    fw, fw_count = calc_lin_char(pc_x_r, pc_y_r, ranges, th=0.2)\n",
    "    feature_12_mat, feature_13_mat = fw, fw_count\n",
    "\n",
    "    discriptor = np.concatenate((   np.expand_dims(d1,axis=1),\n",
    "                                    np.expand_dims(d2,axis=1), \n",
    "                                    np.expand_dims(d3,axis=1), \n",
    "                                    np.expand_dims(feature_3_mat,axis=1),\n",
    "                                    np.expand_dims(feature_6_mat,axis=1),\n",
    "                                    np.expand_dims(feature_7_mat,axis=1),\n",
    "                                    np.expand_dims(feature_8_mat,axis=1),\n",
    "                                    np.expand_dims(feature_9_mat,axis=1),\n",
    "                                    np.expand_dims(feature_10_mat,axis=1),\n",
    "                                    np.expand_dims(feature_11_mat,axis=1),\n",
    "                                    np.expand_dims(feature_12_mat,axis=1),\n",
    "                                    np.expand_dims(feature_13_mat,axis=1)), axis=1)\n",
    "\n",
    "    return (feature_1_mat, feature_2_mat, feature_3_mat, feature_4_mat, feature_5_mat, feature_6_mat), discriptor\n",
    "\n",
    "(feature_1_mat, feature_2_mat, feature_3_mat, feature_4_mat, feature_5_mat, feature_6_mat), discriptor = get_features(ranges, pc_x_r, pc_y_r)\n",
    "discriptor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriptor_avg3 = skimage.measure.block_reduce(discriptor, (D,1), np.mean)\n",
    "D=51\n",
    "scl = StandardScaler()\n",
    "x_f = skimage.measure.block_reduce(x, (D,), np.median)\n",
    "y_f = skimage.measure.block_reduce(y, (D,), np.median)\n",
    "# iii = [1,2,3,4,5,1,2,3,4]\n",
    "# jj = [1,1,1,1,1,2,2,2,2]\n",
    "iii = [1,1,2,2,3,3,4,4,5]\n",
    "jj = [1,2,1,2,1,2,1,2,1]\n",
    "\n",
    "title = []\n",
    "for ii in range(9):\n",
    "    title.append(f\"Feature {ii+1}\")\n",
    "\n",
    "fig = make_subplots(rows=5, cols=2, subplot_titles=tuple(title))\n",
    "for ii, f in enumerate([feature_1_mat, feature_2_mat, feature_3_mat, feature_4_mat, feature_5_mat, feature_6_mat, discriptor[:,5], discriptor[:,6], discriptor[:,7]]):\n",
    "    # c = skimage.measure.block_reduce(scl.fit_transform(np.expand_dims(feature_2_mat,axis=1)), (D,1), np.mean)\n",
    "    c = skimage.measure.block_reduce(scl.fit_transform(np.expand_dims(f,axis=1)), (D,1), np.median)\n",
    "    c = np.squeeze(c*10+20)\n",
    "\n",
    "\n",
    "    mrkr = dict(color='LightSkyBlue', size=2,line=dict(color='MediumPurple', width=0.3))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=pc_x_r[valid_inds_bool][::D], y=pc_y_r[valid_inds_bool][::D], name='walls', mode='markers', marker_color='rgba(135, 206, 250, 0.5)', marker=mrkr),\n",
    "        row=iii[ii], col=jj[ii]\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x[::D], y=y[::D], name='trj'),\n",
    "        row=iii[ii], col=jj[ii]\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_f, y=y_f, name='trj', mode='markers', marker_color=c, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "        row=iii[ii], col=jj[ii]\n",
    "    )\n",
    "    # fig.update_yaxes(\n",
    "    #     scaleanchor=\"x\",\n",
    "    #     scaleratio=1,\n",
    "    # )\n",
    "fig.update_layout(width=800, height=1500, title_text='features')\n",
    "fig.get_subplot(1,2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all_data:\n",
    "#     for l in [ranges_, pc_x_r_, pc_y_r_]:\n",
    "#         print(f'l.shape={l.shape}')\n",
    "for l in [ranges, pc_x_r, pc_y_r]:\n",
    "    print(f'l.shape={l.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_data:\n",
    "    _, discriptor_ = get_features(ranges_, pc_x_r_, pc_y_r_)\n",
    "else:\n",
    "    _, discriptor_ = get_features(ranges, pc_x_r, pc_y_r)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "discriptor_scaled = scaler.fit_transform(discriptor_)\n",
    "\n",
    "print(f'discriptor_scaled shape = {discriptor_scaled.shape}')\n",
    "pca_tmp = PCA()\n",
    "pca_tmp.fit(discriptor_scaled)\n",
    "print(f'pca.explained_variance_ratio_={pca_tmp.explained_variance_ratio_}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(pca_tmp.explained_variance_ratio_)+1), pca_tmp.explained_variance_ratio_.cumsum(),'-o')\n",
    "plt.title('Explained variance components')\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('cumsum evr')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep 80% of variance ==> n_componenets == P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set pca parameters and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2comp = PCA(n_components=7)\n",
    "discriptor_pca = pca_2comp.fit_transform(discriptor_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many clusters needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = False\n",
    "if analysis:\n",
    "    wcss = []\n",
    "    for i in range(1,18):\n",
    "        kmeans_pca = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "        kmeans_pca.fit(discriptor_pca)\n",
    "        wcss.append(kmeans_pca.inertia_)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,18), wcss, marker='o', linestyle='--')\n",
    "    plt.xlabel('number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### elbow method: Need low Inertia and small number of classes\n",
    "Therefore we choose M clusters\n",
    "\n",
    "### Set KMeans parameters and fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
    "kmeans_pca.fit(discriptor_pca)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_data(data, pc_x_r, pc_y_r):\n",
    "    _, discriptor = get_features(data, pc_x_r, pc_y_r)\n",
    "    descriptor_scaled = pca_2comp.transform(scaler.transform(discriptor))\n",
    "\n",
    "    return kmeans_pca.predict(descriptor_scaled), descriptor_scaled\n",
    "\n",
    "# ranges.shape\n",
    "labeled_ranges, descriptor_scaled = label_data(ranges, pc_x_r, pc_y_r)\n",
    "print(f'shape labeled_ranges = {labeled_ranges.shape}')\n",
    "print(f'labeled_ranges[:6]={labeled_ranges[:6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = make_subplots(rows=8, cols=1)\n",
    "c = np.linspace(0, 1, pc_x_r.size)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_1_mat, name='range which is avg its neighbours'),  # , marker_color=c[valid_inds]),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_2_mat, name='num spikes med'),  # , marker_color=c[valid_inds]),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_3_mat, name='num of colinear truplets'),  # , marker_color=c[valid_inds]),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_4_mat, name='num openings med3'),  # , marker_color=c[valid_inds]),\n",
    "    row=4, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_5_mat, name='num openings med5'),  # , marker_color=c[valid_inds]),\n",
    "    row=4, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_4_mat*0.5+0.5*feature_5_mat, name='num openings avrg(med3,med5)'),  # , marker_color=c[valid_inds]),\n",
    "    row=5, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=feature_6_mat, name='avr rng'),  # , marker_color=c[valid_inds]),\n",
    "    row=6, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=discriptor[:,-2], name='opposite'),  # , marker_color=c[valid_inds]),\n",
    "    row=7, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=discriptor[:,-1], name='opposite large'),  # , marker_color=c[valid_inds]),\n",
    "    row=8, col=1\n",
    ")\n",
    "fig.update_layout(width=1000, height=800, title_text=\"Side By Side Subplots\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1\n",
    "if D>1:\n",
    "    discriptor_avg3 = skimage.measure.block_reduce(discriptor, (D,1), np.mean)\n",
    "    x_avg = skimage.measure.block_reduce(x, (D,), np.mean)\n",
    "    y_avg = skimage.measure.block_reduce(y, (D,), np.mean)\n",
    "else:\n",
    "    discriptor_avg3 = discriptor\n",
    "    x_avg = x\n",
    "    y_avg = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "c = np.linspace(0, 1, pc_x_r.size)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=pc_x_r[valid_inds_bool][::21], y=pc_y_r[valid_inds_bool][::21], name='distance', mode='markers'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_avg[::11], y=y_avg[::11], name='distance'),\n",
    "    row=1, col=1\n",
    ")\n",
    "D = 51\n",
    "inds = np.round(len(x_avg)/51.0*np.arange(len(x_avg[::11]))/len(x_avg[::11]))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_avg[::11], y=y_avg[::11], name='distance', mode='markers', marker_color=labeled_ranges[::11]/4.0, customdata=inds, hovertemplate=\"<b>%{customdata}</b>\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    scaleanchor=\"x\",\n",
    "    scaleratio=1,\n",
    ")\n",
    "fig.update_layout(height=800, width=1000, title_text=\"Side By Side Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data_for_infereance.pkl', 'wb') as fid:\n",
    "    pickle.dump(pc_x_r, fid)\n",
    "    pickle.dump(pc_y_r, fid)\n",
    "    pickle.dump(valid_inds_bool, fid)\n",
    "    pickle.dump(labeled_ranges, fid)\n",
    "    pickle.dump(ranges, fid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ranges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "unq = np.unique(labeled_ranges)\n",
    "f = lambda x: np.histogram(x, bins=len(unq), range=(unq[0]-0.5, unq[-1]+0.5))\n",
    "L = len(labeled_ranges)\n",
    "D = 51\n",
    "x_ds = x_avg[:-(L % D)] [::D]\n",
    "y_ds = y_avg[:-(L % D)] [::D]\n",
    "lrs = labeled_ranges[:-(L % D)] \n",
    "if D>1:\n",
    "    label_hist = np.array([f(lr)[0] for lr in list(np.reshape(lrs, (-1, D)))])\n",
    "    # x_avg_2 = skimage.measure.block_reduce(x, (D,), np.mean)\n",
    "    # y_avg_2 = skimage.measure.block_reduce(y, (D,), np.mean)\n",
    "\n",
    "\n",
    "ll = label_hist.shape[0]\n",
    "M = np.zeros((ll, ll))\n",
    "for i in range(ll):\n",
    "    for j in range(i,ll):\n",
    "        if False:\n",
    "            M[i,j] = np.linalg.norm(label_hist[i]-label_hist[j])\n",
    "        else:\n",
    "            M[i,j] = spatial.distance.cosine(label_hist[i],label_hist[j])\n",
    "        M[j,i] = M[i,j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm3 = go.Heatmap(\n",
    "        z=M,\n",
    "        # colorbar = dict(x=0.45), \n",
    "        colorscale='Viridis',\n",
    "        dx=1,\n",
    "        dy=1\n",
    "    )\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)  # , subplot_titles=['Exploration', 'Return'])\n",
    "fig.add_trace(mm3, 1, 1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"likelyhood of same place (histogram comparing)\")  #,yaxis={\"title\": 'time [sec]'},xaxis={\"title\": 'time [sec]',\"tickangle\": 90})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_x = np.expand_dims(x_ds, axis=1).T-np.expand_dims(x_ds, axis=1)\n",
    "M_y = np.expand_dims(y_ds, axis=1).T-np.expand_dims(y_ds, axis=1)\n",
    "Mi = np.expand_dims(np.arange(len(x_ds)), axis=1)\n",
    "Mi = np.repeat(Mi, len(x_ds), axis=1)\n",
    "M = np.sqrt(M_x**2+M_y**2)\n",
    "ind_i, ind_j = np.where(M<0.6)\n",
    "mm3 = go.Heatmap(\n",
    "        z=M,\n",
    "        # colorbar = dict(x=0.45), \n",
    "        colorscale='Viridis',\n",
    "        dx=1,\n",
    "        dy=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)  # , subplot_titles=['Exploration', 'Return'])\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=ind_i, y=ind_j, name='GT', mode='markers', opacity=0.5),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(mm3, 1, 1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"likelyhood of same place (histogram comparing)\")  #,yaxis={\"title\": 'time [sec]'},xaxis={\"title\": 'time [sec]',\"tickangle\": 90})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find distance metric between classes (maybe some classes are more similar to others and require discounted penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_data:\n",
    "    labeled_ranges_, descriptor_scaled_ = label_data(ranges_, pc_x_r=pc_x_r_, pc_y_r=pc_y_r_)\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    c = np.linspace(0, 1, pc_x_r.size)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=pc_x_r_[valid_inds_bool_][::31], y=pc_y_r_[valid_inds_bool_][::31], name='distance', mode='markers'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_[::11], y=y_[::11], name='distance'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_[::11], y=y_[::11], name='distance', mode='markers', marker_color=labeled_ranges_[::11]/4.0),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "    )\n",
    "    fig.update_layout(height=800, width=1000, title_text=\"Side By Side Subplots\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import matlib\n",
    "\n",
    "def soft_clustering_weights(data, cluster_centres, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to calculate the weights from soft k-means\n",
    "    data: Array of data. shape = N x F, for N data points and F Features\n",
    "    cluster_centres: Array of cluster centres. shape = Nc x F, for Nc number of clusters. Input kmeans.cluster_centres_ directly.\n",
    "    param: m - keyword argument, fuzziness of the clustering. Default 2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fuzziness parameter m>=1. Where m=1 => hard segmentation\n",
    "    m = 2\n",
    "    if 'm' in kwargs:\n",
    "        m = kwargs['m']\n",
    "    \n",
    "    Nclusters = cluster_centres.shape[0]\n",
    "    Ndp = data.shape[0]\n",
    "    Nfeatures = data.shape[1]\n",
    "\n",
    "    # Get distances from the cluster centres for each data point and each cluster\n",
    "    EuclidDist = np.zeros((Ndp, Nclusters))\n",
    "    for i in range(Nclusters):\n",
    "        EuclidDist[:,i] = np.sum((data-np.matlib.repmat(cluster_centres[i], Ndp, 1))**2,axis=1)\n",
    "    \n",
    "    # Denominator of the weight from wikipedia:\n",
    "    invWeight = EuclidDist**(2/(m-1))*np.matlib.repmat(np.sum((1./EuclidDist)**(2/(m-1)),axis=1).reshape(-1,1),1,Nclusters)\n",
    "    Weight = 1./invWeight\n",
    "    \n",
    "    return Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = soft_clustering_weights(descriptor_scaled, kmeans_pca.cluster_centers_)\n",
    "confidence = np.max(cw, axis=1)>0.9\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "c = np.linspace(0, 1, pc_x_r.size)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=pc_x_r[valid_inds_bool][::21], y=pc_y_r[valid_inds_bool][::21], name='distance', mode='markers'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_avg[::11], y=y_avg[::11], name='distance'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_avg[confidence][::11], y=y_avg[confidence][::11], name='distance', mode='markers', marker_color=labeled_ranges[confidence][::11]/4.0),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    scaleanchor=\"x\",\n",
    "    scaleratio=1,\n",
    ")\n",
    "fig.update_layout(height=800, width=1000, title_text=\"Side By Side Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.max(cw, axis=1)\n",
    "f = lambda x, w_: np.histogram(x, bins=4, range=(-0.5, 3.5), weights=w_)\n",
    "L = len(labeled_ranges)\n",
    "D = 71\n",
    "lrs = labeled_ranges[:-(L % D)] \n",
    "w = w[:-(L % D)] \n",
    "w = list(np.reshape(w, (-1, D)))\n",
    "if D>1:\n",
    "    label_hist = np.array([f(lr, w_)[0] for lr, w_ in zip(list(np.reshape(lrs, (-1, D))), w)])\n",
    "    x_avg_2 = skimage.measure.block_reduce(x, (D,), np.mean)\n",
    "    y_avg_2 = skimage.measure.block_reduce(y, (D,), np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = label_hist.shape[0]\n",
    "M = np.zeros((ll, ll))\n",
    "for i in range(ll):\n",
    "    for j in range(i,ll):\n",
    "        M[i,j] = np.linalg.norm(label_hist[i]-label_hist[j])\n",
    "        M[j,i] = M[i,j]\n",
    "\n",
    "\n",
    "mm3 = go.Heatmap(\n",
    "        z=M,\n",
    "        # colorbar = dict(x=0.45), \n",
    "        colorscale='Viridis',\n",
    "        dx=2,\n",
    "        dy=2\n",
    "    )\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)  # , subplot_titles=['Exploration', 'Return'])\n",
    "fig.add_trace(mm3, 1, 1)\n",
    "fig.update_layout(height=800, width=800, title_text=\"likelyhood of same place (histogram comparing)\")  #,yaxis={\"title\": 'time [sec]'},xaxis={\"title\": 'time [sec]',\"tickangle\": 90})\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3p7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8c53a5498add80e8ecdd9f0abc10f15143fa72e05e3d640d160415f31ee33e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
